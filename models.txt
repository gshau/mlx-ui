mistralai/Mistral-7B-Instruct-v0.2                      | Mistral-7B-Instruct-v0.2
mistralai/Mistral-7B-v0.1                               | Mistral-7B-v0.1
mistralai/Mistral-7B-Instruct-v0.1                      | Mistral-7B-Instruct-v0.1
mlx-community/dolphin-2.6-mistral-7b-dpo-laser-4bit-mlx | 🐬 Dolphin 2.6 Mistral 7B DPO Laser Q4 (small)
mlx-community/dolphin-2.8-mistral-7b-v02-4bit           | 🐬 Dolphin 2.8 Mistral 7B v02 Q4 (small)
mlx-community/Meta-Llama-3-8B-Instruct-4bit             | 🦙 Llama3 8B Q4 (small)
mlx-community/NeuralBeagle14-7B-4bit-mlx                | 🦮 NeuralBeagle14 7B Q4 (small)
mlx-community/Nous-Hermes-2-Mixtral-8x7B-DPO-4bit       | 🧙 Nous Hermes 2 Mixtral 8x7B DPO Q4 (medium)
mlx-community/stablelm-2-12b-chat-4bit                  | 🔘 StableLM 2 12B Q4 (small)
mlx-community/stablelm-2-zephyr-1_6b-4bit               | 🌬️ StableLM 2 Zephyr 1.6B DPO Q4 (tiny)
mlx-community/TinyDolphin-2.8-1.1b-4bit-mlx             | 🐬 TinyDolphin 2.8 1B Q4 (tiny)
mlx-community/CodeLlama-70b-hf-4bit-MLX                 | 🦙 CodeLlama 70B Q4 (large)
mlx-community/quantized-gemma-2b-it                     | ✨ Gemma 2B Q4 (tiny)
mlx-community/c4ai-command-r-plus-4bit                  | ⌘ Command R + Q4 (very large)
mlx-community/Mixtral-8x22B-4bit                        | 🌪️ Mixtral 8x22B Q4 (large)
